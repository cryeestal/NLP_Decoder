2021-11-27 02:36:04,878 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,880 Model: "TextClassifier(
  (loss_function): CrossEntropyLoss()
  (document_embeddings): DocumentLSTMEmbeddings(
    (embeddings): StackedEmbeddings(
      (list_embedding_0): WordEmbeddings('glove')
      (list_embedding_1): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.25, inplace=False)
          (encoder): Embedding(275, 100)
          (rnn): LSTM(100, 1024)
          (decoder): Linear(in_features=1024, out_features=275, bias=True)
        )
      )
      (list_embedding_2): FlairEmbeddings(
        (lm): LanguageModel(
          (drop): Dropout(p=0.25, inplace=False)
          (encoder): Embedding(275, 100)
          (rnn): LSTM(100, 1024)
          (decoder): Linear(in_features=1024, out_features=275, bias=True)
        )
      )
    )
    (word_reprojection_map): Linear(in_features=2148, out_features=256, bias=True)
    (rnn): GRU(256, 512)
    (dropout): Dropout(p=0.5, inplace=False)
  )
  (decoder): Linear(in_features=512, out_features=2, bias=True)
  (weights): None
  (weight_tensor) None
)"
2021-11-27 02:36:04,880 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,881 Corpus: "Corpus: 4212 train + 527 dev + 527 test sentences"
2021-11-27 02:36:04,882 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,883 Parameters:
2021-11-27 02:36:04,884  - learning_rate: "0.1"
2021-11-27 02:36:04,886  - mini_batch_size: "32"
2021-11-27 02:36:04,887  - patience: "3"
2021-11-27 02:36:04,888  - anneal_factor: "0.5"
2021-11-27 02:36:04,888  - max_epochs: "5"
2021-11-27 02:36:04,889  - shuffle: "True"
2021-11-27 02:36:04,891  - train_with_dev: "False"
2021-11-27 02:36:04,891  - batch_growth_annealing: "False"
2021-11-27 02:36:04,892 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,893 Model training base path: "."
2021-11-27 02:36:04,894 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,895 Device: cpu
2021-11-27 02:36:04,895 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:04,896 Embeddings storage mode: cpu
2021-11-27 02:36:04,932 ----------------------------------------------------------------------------------------------------
2021-11-27 02:36:44,910 epoch 1 - iter 13/132 - loss 0.00630704 - samples/sec: 10.45 - lr: 0.100000
2021-11-27 02:37:28,216 epoch 1 - iter 26/132 - loss 0.00439220 - samples/sec: 9.63 - lr: 0.100000
2021-11-27 02:38:05,936 epoch 1 - iter 39/132 - loss 0.00352365 - samples/sec: 11.08 - lr: 0.100000
2021-11-27 02:39:10,523 epoch 1 - iter 52/132 - loss 0.00311208 - samples/sec: 6.47 - lr: 0.100000
2021-11-27 02:39:54,103 epoch 1 - iter 65/132 - loss 0.00268852 - samples/sec: 9.61 - lr: 0.100000
2021-11-27 02:40:41,619 epoch 1 - iter 78/132 - loss 0.00251778 - samples/sec: 8.80 - lr: 0.100000
2021-11-27 02:41:25,804 epoch 1 - iter 91/132 - loss 0.00222376 - samples/sec: 10.78 - lr: 0.100000
2021-11-27 02:42:04,668 epoch 1 - iter 104/132 - loss 0.00201304 - samples/sec: 10.71 - lr: 0.100000
2021-11-27 02:42:48,892 epoch 1 - iter 117/132 - loss 0.00187424 - samples/sec: 9.42 - lr: 0.100000
2021-11-27 02:43:21,982 epoch 1 - iter 130/132 - loss 0.00172246 - samples/sec: 12.60 - lr: 0.100000
2021-11-27 02:43:25,626 ----------------------------------------------------------------------------------------------------
2021-11-27 02:43:25,628 EPOCH 1 done: loss 0.0017 - lr 0.1000000
2021-11-27 02:44:17,167 DEV : loss 0.0010504581732675433 - f1-score (micro avg)  0.9905
2021-11-27 02:44:17,427 BAD EPOCHS (no improvement): 0
2021-11-27 02:44:17,429 saving best model
2021-11-27 02:44:23,118 ----------------------------------------------------------------------------------------------------
2021-11-27 02:45:00,421 epoch 2 - iter 13/132 - loss 0.00045675 - samples/sec: 11.22 - lr: 0.100000
2021-11-27 02:45:43,759 epoch 2 - iter 26/132 - loss 0.00046877 - samples/sec: 10.12 - lr: 0.100000
2021-11-27 02:46:27,267 epoch 2 - iter 39/132 - loss 0.00052584 - samples/sec: 9.58 - lr: 0.100000
2021-11-27 02:47:07,016 epoch 2 - iter 52/132 - loss 0.00056043 - samples/sec: 10.48 - lr: 0.100000
2021-11-27 02:47:44,710 epoch 2 - iter 65/132 - loss 0.00054459 - samples/sec: 11.06 - lr: 0.100000
2021-11-27 02:48:24,621 epoch 2 - iter 78/132 - loss 0.00050766 - samples/sec: 10.45 - lr: 0.100000
2021-11-27 02:49:04,403 epoch 2 - iter 91/132 - loss 0.00061080 - samples/sec: 10.48 - lr: 0.100000
2021-11-27 02:49:42,365 epoch 2 - iter 104/132 - loss 0.00069921 - samples/sec: 11.01 - lr: 0.100000
2021-11-27 02:50:36,824 epoch 2 - iter 117/132 - loss 0.00071899 - samples/sec: 8.09 - lr: 0.100000
2021-11-27 02:51:15,192 epoch 2 - iter 130/132 - loss 0.00071170 - samples/sec: 10.86 - lr: 0.100000
2021-11-27 02:51:20,240 ----------------------------------------------------------------------------------------------------
2021-11-27 02:51:20,241 EPOCH 2 done: loss 0.0007 - lr 0.1000000
2021-11-27 02:52:09,943 DEV : loss 0.0009152860147878528 - f1-score (micro avg)  0.9943
2021-11-27 02:52:10,224 BAD EPOCHS (no improvement): 0
2021-11-27 02:52:10,227 saving best model
2021-11-27 02:52:15,596 ----------------------------------------------------------------------------------------------------
2021-11-27 02:52:57,079 epoch 3 - iter 13/132 - loss 0.00155330 - samples/sec: 10.06 - lr: 0.100000
2021-11-27 02:53:37,975 epoch 3 - iter 26/132 - loss 0.00091675 - samples/sec: 10.19 - lr: 0.100000
2021-11-27 02:54:24,030 epoch 3 - iter 39/132 - loss 0.00070705 - samples/sec: 9.05 - lr: 0.100000
2021-11-27 02:54:57,212 epoch 3 - iter 52/132 - loss 0.00084336 - samples/sec: 12.57 - lr: 0.100000
2021-11-27 02:55:36,235 epoch 3 - iter 65/132 - loss 0.00078044 - samples/sec: 10.68 - lr: 0.100000
2021-11-27 02:56:11,891 epoch 3 - iter 78/132 - loss 0.00073675 - samples/sec: 11.68 - lr: 0.100000
2021-11-27 02:56:50,825 epoch 3 - iter 91/132 - loss 0.00069508 - samples/sec: 10.75 - lr: 0.100000
2021-11-27 02:57:27,329 epoch 3 - iter 104/132 - loss 0.00063322 - samples/sec: 11.42 - lr: 0.100000
2021-11-27 02:58:11,004 epoch 3 - iter 117/132 - loss 0.00063386 - samples/sec: 9.54 - lr: 0.100000
2021-11-27 02:58:56,482 epoch 3 - iter 130/132 - loss 0.00058690 - samples/sec: 9.16 - lr: 0.100000
2021-11-27 02:59:00,538 ----------------------------------------------------------------------------------------------------
2021-11-27 02:59:00,540 EPOCH 3 done: loss 0.0006 - lr 0.1000000
2021-11-27 02:59:56,007 DEV : loss 0.0009027255582623184 - f1-score (micro avg)  0.9943
2021-11-27 02:59:56,366 BAD EPOCHS (no improvement): 0
2021-11-27 02:59:56,371 ----------------------------------------------------------------------------------------------------
2021-11-27 03:00:46,653 epoch 4 - iter 13/132 - loss 0.00028038 - samples/sec: 8.31 - lr: 0.100000
2021-11-27 03:01:34,048 epoch 4 - iter 26/132 - loss 0.00063465 - samples/sec: 8.79 - lr: 0.100000
2021-11-27 03:02:10,649 epoch 4 - iter 39/132 - loss 0.00046845 - samples/sec: 11.39 - lr: 0.100000
2021-11-27 03:02:56,993 epoch 4 - iter 52/132 - loss 0.00042514 - samples/sec: 9.00 - lr: 0.100000
2021-11-27 03:03:35,877 epoch 4 - iter 65/132 - loss 0.00058004 - samples/sec: 10.71 - lr: 0.100000
2021-11-27 03:04:15,592 epoch 4 - iter 78/132 - loss 0.00054224 - samples/sec: 10.50 - lr: 0.100000
2021-11-27 03:04:47,730 epoch 4 - iter 91/132 - loss 0.00048858 - samples/sec: 12.98 - lr: 0.100000
2021-11-27 03:05:29,966 epoch 4 - iter 104/132 - loss 0.00053926 - samples/sec: 10.50 - lr: 0.100000
2021-11-27 03:06:05,083 epoch 4 - iter 117/132 - loss 0.00051160 - samples/sec: 11.86 - lr: 0.100000
2021-11-27 03:06:49,159 epoch 4 - iter 130/132 - loss 0.00049213 - samples/sec: 9.44 - lr: 0.100000
2021-11-27 03:06:53,650 ----------------------------------------------------------------------------------------------------
2021-11-27 03:06:53,650 EPOCH 4 done: loss 0.0005 - lr 0.1000000
2021-11-27 03:07:47,337 DEV : loss 0.0008315626764670014 - f1-score (micro avg)  0.9924
2021-11-27 03:07:47,611 BAD EPOCHS (no improvement): 1
2021-11-27 03:07:47,614 ----------------------------------------------------------------------------------------------------
2021-11-27 03:08:21,969 epoch 5 - iter 13/132 - loss 0.00006935 - samples/sec: 12.17 - lr: 0.100000
2021-11-27 03:09:02,420 epoch 5 - iter 26/132 - loss 0.00010075 - samples/sec: 10.31 - lr: 0.100000
2021-11-27 03:09:43,770 epoch 5 - iter 39/132 - loss 0.00039263 - samples/sec: 10.73 - lr: 0.100000
2021-11-27 03:10:24,035 epoch 5 - iter 52/132 - loss 0.00047680 - samples/sec: 10.34 - lr: 0.100000
2021-11-27 03:11:07,207 epoch 5 - iter 65/132 - loss 0.00042229 - samples/sec: 9.65 - lr: 0.100000
2021-11-27 03:11:44,077 epoch 5 - iter 78/132 - loss 0.00044049 - samples/sec: 11.32 - lr: 0.100000
2021-11-27 03:12:24,319 epoch 5 - iter 91/132 - loss 0.00043944 - samples/sec: 10.36 - lr: 0.100000
2021-11-27 03:13:10,956 epoch 5 - iter 104/132 - loss 0.00045054 - samples/sec: 8.94 - lr: 0.100000
2021-11-27 03:13:59,752 epoch 5 - iter 117/132 - loss 0.00043080 - samples/sec: 8.54 - lr: 0.100000
2021-11-27 03:14:41,587 epoch 5 - iter 130/132 - loss 0.00043073 - samples/sec: 9.97 - lr: 0.100000
2021-11-27 03:14:51,559 ----------------------------------------------------------------------------------------------------
2021-11-27 03:14:51,562 EPOCH 5 done: loss 0.0004 - lr 0.1000000
2021-11-27 03:15:43,057 DEV : loss 0.0008264697389677167 - f1-score (micro avg)  0.9905
2021-11-27 03:15:43,326 BAD EPOCHS (no improvement): 2
2021-11-27 03:15:49,300 ----------------------------------------------------------------------------------------------------
2021-11-27 03:15:49,345 loading file best-model.pt
2021-11-27 03:16:36,426 0.9962	0.9962	0.9962	0.9962
2021-11-27 03:16:36,429 
Results:
- F-score (micro) 0.9962
- F-score (macro) 0.9934
- Accuracy 0.9962

By class:
              precision    recall  f1-score   support

         ham     0.9977    0.9977    0.9977       435
        spam     0.9891    0.9891    0.9891        92

   micro avg     0.9962    0.9962    0.9962       527
   macro avg     0.9934    0.9934    0.9934       527
weighted avg     0.9962    0.9962    0.9962       527
 samples avg     0.9962    0.9962    0.9962       527

2021-11-27 03:16:36,429 ----------------------------------------------------------------------------------------------------
